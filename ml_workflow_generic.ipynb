{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b225254f",
   "metadata": {},
   "source": [
    "<h2>General Data Preprocessing and Logistic Regression Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b551782a",
   "metadata": {},
   "source": [
    "<p>It has an example codebase for preparing data for machine learning and modelling with logistic regression. The code is made up of these major steps:\n",
    "\n",
    "Data loading and feature selection.\n",
    "Data preprocessing, including handling missing values and feature standardization.\n",
    "Classification using logistic regression.\n",
    "Model performance evaluation and visualization.\n",
    "\n",
    "These methods can be used for a wide range of machine-learning tasks, as shown by the Titanic survival prediction case. </p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e995e9a",
   "metadata": {},
   "source": [
    "<h3>1: Data Loading and Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f56085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ceb4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for labels and columns\n",
    "LABEL_COLUMN = 'survived'\n",
    "CATEGORICAL_COLUMNS = ['sex', 'embarked']\n",
    "NUMERICAL_COLUMNS = ['age', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "def load_and_preprocess_data(csv_address):\n",
    "    data = pd.read_csv(csv_address, na_values='?')\n",
    "    \n",
    "    # Extrat label and feature dataset from orignal data\n",
    "    y = data[LABEL_COLUMN]\n",
    "    X = data.drop(columns=LABEL_COLUMN)\n",
    "\n",
    "    # Standardize feature data\n",
    "    # Seperate categorical feature and nunmerical feature data\n",
    "    selected_columns = CATEGORICAL_COLUMNS + NUMERICAL_COLUMNS \n",
    "    X_filtered = X[selected_columns]\n",
    "    \n",
    "    # Standardize feature\n",
    "    # convert the categorical data into numeric feature through pipline\n",
    "    scaler_cat = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "    scaler_num = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', scaler_num, NUMERICAL_COLUMNS),\n",
    "            ('cat', scaler_cat, CATEGORICAL_COLUMNS)\n",
    "        ])\n",
    "    \n",
    "    return preprocessor, X_filtered, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0446204",
   "metadata": {},
   "source": [
    "<h3>Module 2: Model Training and Evaluation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da97b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "492035d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(preprocessor, X_filtered, y):\n",
    "    # Hyperparameter Optimization with defaulr param_grid\n",
    "    pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs', random_state=42, max_iter=5000))\n",
    "    param_grid = {\n",
    "        'logisticregression__penalty': ['l2'],\n",
    "        'logisticregression__C': [0.001, 0.01, 0.1, 1.0]\n",
    "    }\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True)\n",
    "    \n",
    "    scores = cross_validate(grid, X_filtered, y, scoring='balanced_accuracy', cv=3, return_train_score=True, error_score='raise')\n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_filtered, y, random_state=42)\n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    accuracy = grid.score(X_test, y_test)\n",
    "    \n",
    "    return df_scores, grid.best_params_, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d227f7",
   "metadata": {},
   "source": [
    "<h3>Module 3: Main Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    csv_address = \"https://cdn.coggle.club/titanic_openml.csv\"\n",
    "    preprocessor, X_filtered, y = load_and_preprocess_data(csv_address)\n",
    "    df_scores, best_params, accuracy = train_and_evaluate_model(preprocessor, X_filtered, y)\n",
    "    print(\"Model Performance:\")\n",
    "    print(df_scores[['train_score', 'test_score']].boxplot())\n",
    "    print(\"Best Model Parameters:\", best_params)\n",
    "    print(f'Accuracy score of the LogisticRegression model is {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
